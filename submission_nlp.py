# -*- coding: utf-8 -*-
"""Submission NLP

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oKJ83dAt1d_roWoXV631tCFp1-wERcut

**Izdiharti Noni Pertiwi** 

> dataset : movie genre data

> Sumber kaggle : https://www.kaggle.com/lokkagle/movie-genre-data
"""

from google.colab import drive
drive.mount('/content/gdrive')

#import pandas
import pandas as pd

df = pd.read_csv("/content/drive/MyDrive/Submission1/kaggle_movie_train.csv")
df.head(10)

#data columns
df.columns

#total data
df.shape

# info data
df.info()

#categories genre
df.genre.value_counts()

# delete columns (unused column)
DF=df.drop(columns=['id'])
DF

# Menghapus genre selain 5 genre tersebut
DF = DF[~DF['genre'].isin(['drama','thriller','other','adventure','romance'])]
DF['genre'].value_counts()

category = pd.get_dummies(DF.genre)
DF = pd.concat([DF, category], axis=1)
DF = DF.drop(columns='genre')
DF

# Mengubah tipe data menjadi str dan numpy array 
text = DF['text'].astype(str)
label = DF[['action', 'comedy','horror','sci-fi']].values

from sklearn.model_selection import train_test_split
text_latih, text_test, label_latih, label_test = train_test_split(text, label, test_size=0.2)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
 
tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(text_latih) 
tokenizer.fit_on_texts(text_test)
 
sekuens_latih = tokenizer.texts_to_sequences(text_latih)
sekuens_test = tokenizer.texts_to_sequences(text_test)
 
padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
model = Sequential([
    Embedding(input_dim=5000, output_dim=16),
    LSTM(64),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(4, activation='softmax')
])
Adam(learning_rate=0.00146, name='Adam')
model.compile(optimizer = 'Adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])
model.summary()

# callback
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.9 and logs.get('val_accuracy')>0.9):
      self.model.stop_training = True
      print("\nThe accuracy of the training set and the validation set has reached > 90%!")
callbacks = myCallback()

num_epochs = 50
history = model.fit(padded_latih, label_latih, epochs=num_epochs, 
                    validation_data=(padded_test, label_test), verbose=2, callbacks=[callbacks])

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi Model')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()